{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134372bd-110d-49f3-ba4d-adbc328bb227",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e921a-7b0f-4ecc-a85b-4b2feeefd925",
   "metadata": {},
   "source": [
    "### Installl Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc7e30a-4abc-487c-8598-def1cded2341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade -q openai langchain langchain-openai langchain-community langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0887491-8a14-4fc5-8003-04444d3c3306",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038ad78a-9784-4150-bcad-d535e1cc0f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Loaded True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "print(\"API Key Loaded\", os.environ.get('OPENAI_API_KEY') is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7b72bc-5612-4e48-b2e1-3e94ae6fd60a",
   "metadata": {},
   "source": [
    "### Generate a Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c35913-4d15-4f07-b248-1022cc5c03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92911c81-d84d-400f-9cfb-0073d660c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        'system',\n",
    "        '''\n",
    "        You are an expert social media strategist specialized in crafting viral tweets.\n",
    "        Your goals:\n",
    "        1. Create engaging and impactful tweets that resonate with the target audience\n",
    "        2. Use appropriate hashtags, emojis, and trending topics when relevant\n",
    "        3. Maintain brand voice while maximizing engagement potential\n",
    "        4. Keep tweets concise yet impactful within Twitter's character limit\n",
    "        5. Consider timing and current trends in the content\n",
    "\n",
    "        If provided with feedback:\n",
    "        - Analyze the feedback carefully\n",
    "        - Incorporate suggested improvements\n",
    "        - Maintain the core message while enhancing engagement\n",
    "        - Ensure each iteration improves upon the previous version\n",
    "\n",
    "        Remember: A great tweet combines clarity, creativity, and call-to-action while feeling authentic.\n",
    "        '''\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name='messages')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aba96934-750e-49e4-88c1-978e34d82d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.7)\n",
    "generation_chain = generation_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b73c207-6e89-48d5-be1a-44e172ed1151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ‚ú® Did you know? LLMs can reflect on their own responses to enhance accuracy and relevance! ü§ñüí° By evaluating their outputs, they learn from mistakes and adapt dynamically. This self-improvement cycle is shaping the future of AI! üåü What innovations are you most excited about? #AI #MachineLearning #TechTrends #LLM #Innovation"
     ]
    }
   ],
   "source": [
    "tweet = ''\n",
    "request = HumanMessage(\n",
    "    content = '''\n",
    "    Generate a tweet about Reflection in AI - how LLMs can evaluate and improve their own responses. \n",
    "    Make it exciting and educational for tech enthusiasts and developers.\n",
    "    '''\n",
    ")\n",
    "\n",
    "for chunk in generation_chain.stream(\n",
    "    {\n",
    "        'messages':[request]\n",
    "    }\n",
    "):\n",
    "    print(chunk.content, end='')\n",
    "    tweet += chunk.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5f718-3bd7-4ac7-a18a-95eee265a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e04c3-dcc4-44bf-b4b6-f63039047950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6a885-c576-40a3-9e3f-d9c381fb4f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8e5299-473e-4095-9393-9578f3afe3d1",
   "metadata": {},
   "source": [
    "### Reflect On the tweet and Re generate Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cad98fe-84ba-436d-bf5f-0302e457d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        'system',\n",
    "        '''\n",
    "        You are a senior social media analyst with expertise in content optimization.\n",
    "        Your role is to provide detailed analysis and actionable feedback on tweets.\n",
    "\n",
    "        Analyze the following aspects:\n",
    "        1. Engagement Potential:\n",
    "           - Hook and attention-grabbing elements\n",
    "           - Call-to-action effectiveness\n",
    "           - Viral potential\n",
    "\n",
    "        2. Content Structure:\n",
    "           - Clarity and conciseness\n",
    "           - Hashtag usage and placement\n",
    "           - Emoji effectiveness\n",
    "\n",
    "        3. Technical Elements:\n",
    "           - Character count optimization\n",
    "           - Formatting and readability\n",
    "           - Link placement (if applicable)\n",
    "\n",
    "        4. Brand Alignment:\n",
    "           - Tone and voice consistency\n",
    "           - Message clarity\n",
    "           - Target audience appeal\n",
    "\n",
    "        Provide specific, actionable recommendations for improvement in each area.\n",
    "        Your feedback should be constructive, detailed, and focused on maximizing impact.\n",
    "        '''\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name='messages')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d96981ac-559c-4857-b9b3-7a46d41417d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Analysis of the Tweet\n",
      "\n",
      "#### 1. Engagement Potential:\n",
      "- **Hook and Attention-Grabbing Elements**: The use of \"Did you know?\" is engaging, but it could be enhanced with a more provocative statement or question to draw readers in even further. Consider starting with a surprising fact about LLMs and their capabilities.\n",
      "- **Call-to-Action Effectiveness**: The CTA \"What innovations are you most excited about?\" invites interaction, which is good. However, it could be more specific to encourage more detailed responses.\n",
      "- **Viral Potential**: The tweet has viral potential due to the topic's relevance and interest in AI, but it could leverage urgency or controversy to increase shares.\n",
      "\n",
      "#### 2. Content Structure:\n",
      "- **Clarity and Conciseness**: The tweet is mostly clear but could be more concise. Some sentences can be streamlined to enhance readability.\n",
      "- **Hashtag Usage and Placement**: Hashtags are relevant and well-placed, but limiting to 2-3 hashtags may improve visibility and engagement. Consider using trending or more niche hashtags related to AI advancements.\n",
      "- **Emoji Effectiveness**: The emojis add a fun element but could be reduced or selectively used to avoid overwhelming the message.\n",
      "\n",
      "#### 3. Technical Elements:\n",
      "- **Character Count Optimization**: The tweet currently has 225 characters. Aim for around 120-140 characters to allow for retweets and add more context if necessary.\n",
      "- **Formatting and Readability**: Breaking the tweet into shorter sentences or using bullet points (if appropriate) could improve readability.\n",
      "- **Link Placement (if applicable)**: If there‚Äôs a relevant article or resource, consider including a link to provide additional context and depth.\n",
      "\n",
      "#### 4. Brand Alignment:\n",
      "- **Tone and Voice Consistency**: The tone is enthusiastic and educational, which aligns well with the tech enthusiast audience. Ensure this tone is consistent across future content.\n",
      "- **Message Clarity**: While the message is clear, it could be more focused on a singular idea to enhance impact.\n",
      "- **Target Audience Appeal**: The content appeals to tech enthusiasts but could benefit from more technical details or examples that developers might appreciate.\n",
      "\n",
      "### Specific, Actionable Recommendations:\n",
      "\n",
      "1. **Engagement Potential**:\n",
      "   - Start with a bold statement or question, such as: \"Imagine if AI could learn from its mistakes in real-time! üßê\"\n",
      "   - Make the CTA more specific, e.g., \"What groundbreaking AI innovations do you think will emerge next?\"\n",
      "\n",
      "2. **Content Structure**:\n",
      "   - Streamline the text: \"LLMs can self-evaluate their responses to boost accuracy and relevance! By learning from mistakes, they adapt dynamically‚Äîshaping the future of AI! üåü\"\n",
      "   - Limit hashtags to 2-3: perhaps #AI and #LLM, and consider adding a trending hashtag if applicable.\n",
      "\n",
      "3. **Technical Elements**:\n",
      "   - Aim for a character count under 140: \"Imagine if AI could learn from its mistakes! ü§ñ LLMs self-evaluate responses to enhance accuracy and relevance. What AI innovations excite you? #AI #LLM\"\n",
      "   - If a link is available, add it at the end for further reading.\n",
      "\n",
      "4. **Brand Alignment**:\n",
      "   - Maintain the enthusiastic tone but ensure that technical aspects are accessible to a broader audience.\n",
      "   - Consider incorporating a real-world example or a mini-case study of LLM self-improvement to enhance clarity and relatability.\n",
      "\n",
      "### Revised Tweet Example:\n",
      "\"Imagine if AI could learn from its mistakes in real-time! ü§ñ‚ú® LLMs self-evaluate their responses to boost accuracy and relevance, shaping the future of tech! What groundbreaking AI innovations excite you? #AI #LLM\" (139 characters)"
     ]
    }
   ],
   "source": [
    "reflect_chain = reflection_prompt | llm\n",
    "\n",
    "reflection = ''\n",
    "for chunk in reflect_chain.stream(\n",
    "    {\n",
    "        'messages':[\n",
    "            request, HumanMessage(content=tweet)\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    print(chunk.content, end='')\n",
    "    reflection += chunk.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3775b82-3ccb-437b-82fc-282db17123f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Imagine if AI could learn from its mistakes in real-time! ü§ñ‚ú® LLMs self-evaluate their responses to boost accuracy and relevance, shaping the future of tech! What groundbreaking AI innovations are you most excited about? #AI #LLM #TechTrends"
     ]
    }
   ],
   "source": [
    "for chunk in generation_chain.stream(\n",
    "    {\n",
    "        'messages':[\n",
    "            request, AIMessage(content=tweet), HumanMessage(content=reflection)\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    print(chunk.content, end ='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253e421-1614-46cd-ac72-810589443122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc291fbb-4512-4eed-8845-1478025f4853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f5a5a-7af3-4178-8ef8-20033e88dabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffedbc7-17c2-4597-b60a-268818018160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ed4e5-79ea-42fb-b9ea-82aabaf53979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b1aef-fed6-472a-96f6-56fee0ae3a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2648b9-8b79-4075-b9e6-b12909e2f3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1551fe-27b4-4229-a753-41dc4301dcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bd4d4-bec3-4886-ba42-0320447d5378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844ea4d-607e-4343-9ee8-74687e4f9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbec9ff-8478-4a8e-9440-dd55d5e56be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca62be-927f-40eb-830f-62185e9c2929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3eb6bf-6d0a-42ab-b6e4-8b97b4b20ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e32c3-525d-481c-82d5-25ed12c84856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e9696-85fd-43f3-abf6-ae8372da9824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ab02f-0ff1-4f60-83ec-39a82e7bc599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6c1b4-7e14-49ea-9afe-8675bf7443a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c388f64-91eb-4754-a863-8d3dc3676784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc72500-6a86-4559-9f63-79ec5c1b3b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
